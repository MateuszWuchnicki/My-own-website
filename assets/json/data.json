{
    "PL": {
        "menu1": "START",
        "menu2": "O MNIE",
        "menu3": "ŻYCIORYS",
        "menu4": "UMIEJĘTNOŚCI",
        "menu5": "PORTFOLIO",
        "menu6": "KONTAKT",
        "menu7": "Zaprojektowane przez &copy;&nbsp;",
        "home1": "Cześć, jestem",
        "home2": "Mateusz Wuchnicki",
        "home3": "Specjalista ds. GIS, Analityk danych&#10;oraz pasjonat Data Science i&nbsp;uczenia&nbsp;maszynowego&#10;z Krakowa, Polska",
        "home4": "POBIERZ CV",
        "home5": "Wersja polska",
        "home6": "Wersja angielska",
        "about1": "Imię i nazwisko ",
        "about2": "Urodziny ",
        "about3": "1 lutego 1994",
        "about4": "E-mail ",
        "about5": "Adres ",
        "about6": "Kraków, Polska",
        "about7": "Telefon ",
        "about8": "O mnie",
        "about9": "Specjalista ds. GIS, fotogrametrii&#10;i teledetekcji",
        "about10": "Jestem wykwalifikowanym inżynierem z ponad siedmioletnim doświadczeniem. Brałem czynny udział w wielu projektach komercyjnych i&nbsp;badawczo-rozwojowych. Wykonywałem wiele analiz przestrzennych, opracowywałem ortofotomapy, modele terenu oraz chmury punktów pochodzące z lotniczego skaningu laserowego, a także pisałem sprawozdania techniczne. Byłem odpowiedzialny między innymi za planowanie, monitorowanie i koordynowanie misji lotniczych, których celem było pozyskanie wysokorozdzielczych zdjęć lotniczych i chmury punktów ALS. Posiadam wyjątkowe umiejętności analityczne, organizacyjne, planistyczne i&nbsp;komunikacyjne oraz skoncentrowane podejście do pracy w&nbsp;ustrukturyzowanym środowisku. Poszukuję pracy, w&nbsp;której wykorzystam moje umiejętności i będę mógł dalej się rozwijać w szerokopojętej branży GIS.",
        "about11": "Hobby &#124; Zainteresowania",
        "about12": "Zdobywanie szczytów górskich",
        "about13": "Bieganie",
        "about14": "Finanse osobiste&#10;i inwestowanie",
        "about15": "Data Science&#10;&amp; Analysis",
        "about16": "E-Sport",
        "resume1": "Życiorys",
        "resume2": "„Dobre decyzje są wynikiem doświadczenia, a doświadczenie zdobywa się poprzez podejmowanie błędnych decyzji.”",
        "resume3": "&ndash; Mark Twain",
        "resume4": "Doświadczenie",
        "resume5": "Menager ds. technicznych w dziale technologii lotniczych",
        "resume6": "SmallGIS Sp. z o.o. <span>&#124;</span> Kraków",
        "resume7": "W wewnątrznej strukturze firmy pełniłem funkcję menagera do spraw technicznych w dziale technologii lotniczych. Byłem odpowiedzialny za&nbsp;sprawne działanie i merytoryczne wsparcie zespołu analityków oraz&nbsp;personelu technicznego. Równocześnie sprawowałem funkcję nadzoru operacyjnego misji lotniczych.",
        "resume8": "Do moich obowiązków należało:",
        "resume9": "Koordynacja projektów analitycznych i geoprzestrzennych",
        "resume10": "Optymalizacja procesów przetwarzania danych i raportowania wyników przy użyciu Python",
        "resume11": "Analiza dużych zbiorów danych i przygotowywanie raportów",
        "resume12": "Identyfikacja ryzyk i ich wpływu na realizację projektów",
        "resume13": "Opracowywanie raportów i wizualizacji danych dla interesariuszy",
        "resume14": "Organizowanie szkoleń dla zespołu technicznego",
        "resume15": "Identyfikowanie potencjalnych zagrożeń związanych z realizacją projektów",
        "resume16": "Analiza i modelowanie danych przestrzennych na potrzeby projektów biznesowych",
        "resume17": "Analityk ds. GIS, Fotogrametrii &#10;i Teledetekcji",
        "resume18": "Pracując w dziale technologii lotniczych, zdobyłem szerokie doświadczenie w analizie danych i zarządzaniu projektami. Odpowiadałem za planowanie, koordynację oraz optymalizację procesów pozyskiwania i przetwarzania danych geoprzestrzennych.",
        "resume19": "Przeprowowadzanie analiz geoprzestrzennych",
        "resume20": "Opracowywanie ortofotomap lotniczych oraz danych LiDAR (ALS)",
        "resume21": "Przetwarzanie zobrazowań satelitarnych oraz hiperspektralnych",
        "resume22": "Komplekswe planowanie, monitorowanie i koordynacja misji lotniczych",
        "resume23": "Koordynowanie działań z różnymi organami i jednostkami wojskowymi",
        "resume24": "Zarządzanie dokumentacją techniczną i operacyjną",
        "resume25": "Bezpośredni kontakt z klientami",
        "resume26": "Technik GIS",
        "resume27": "Wykorzystywałem narzędzia GIS oraz analityczne do przetwarzania i analizy danych przestrzennych. Uczestniczyłem w projektach związanych z danymi przestrzennymi oraz wdrażaniem procesów analitycznych.",
        "resume28": "Opracowywanie ortofotomap lotniczych oraz danych LiDAR",
        "resume29": "Przeprowadzanie analiz przestrzennych",
        "resume30": "Przetwarzanie danych wektorowych i rastrowych",
        "resume31": "Prowadzenie szkoleń z zakresu analiz i oprogramowania GIS",
        "resume32": "Bezpośredni kontakt z klientami",
        "resume33": "Stażysta",
        "resume34": "Podczas stażu zdobyłem praktyczne doświadczenie w analizie danych i raportowaniu. Brałem udział w projektach związanych z analizą geoprzestrzenną i optymalizacją procesów biznesowych.",
        "resume35": "Przetwarzanie wysokorozdzielczych zdjęć lotniczych i zobrazowań satelitarnych",
        "resume36": "Tworzenie raportów oraz sprawozdań dotyczących analiz i projektów",
        "resume37": "Przetwarzanie i migracja danych z różnych źródeł",
        "resume38": "Przygotowywania dokumentajci technicznej",
        "resume39": "Technik fotogrametrii",
        "resume40": "GEOCARTIS Sp. z o.o. Sp. K. <span>&#124;</span> Poznań",
        "resume41": "Specjalizowałem się w tworzeniu modeli 3D i analizie danych geoprzestrzennych. Moja praca obejmowała przetwarzanie chmur punktów oraz optymalizację procesów analitycznych.",
        "resume42": "Tworzenie modeli 3D na potrzeby analiz biznesowych",
        "resume43": "Opracowywanie wizualizacji danych na potrzeby dla projektów komercyjnych",
        "resume44": "Analiza danych przestrzennych i tworzenie szczegółówych raportów",
        "resume45": "Współpraca z zespołami analitycznymi w celu optymalizacji procesów",
        "resume46": "GEOMAT Sp. z o.o. <span>&#124;</span> Poznań",
        "resume47": "Trzy miesięczny staż w branży geodezyjnej, w trakcie którego poznałem narzędzia do projektowania map i baz danych. Udoskonaliłem swoje umiejętności posługiwania się instrumentami geodezyjnymi.",
        "resume48": "Aktualizacja bazy BDOT10k oraz redakcję kartograficzna bazy KARTO10k",
        "resume49": "Kontrola atrybutów obiektów bazy GESUT oraz tworzenie map tematycznych",
        "resume50": "Wykonywanie pomiarów geodezyjnych",
        "resume51": "Kursy i szkolenia",
        "resume52": "Sages, Kodołamacz <span>&#124;</span> Warszawa",
        "resume53": "Kurs online, 420 godz.",
        "resume54": "Zaawansowany kurs Data Science i analizy danych, który obejmował praktyczne wykorzystanie języka Python oraz narzędzi analitycznych do eksploracji, modelowania i wizualizacji danych. Kurs był prowadzony w formie intensywnych warsztatów z rzeczywistymi studiami przypadków.",
        "resume55": "Zakres kursu i zdobyte umiejętności:",
        "resume56": "Analiza danych i programowanie w Pythonie",
        "resume57": "Zaawansowana analiza danych z wykorzystaniem NumPy, Pandas",
        "resume58": "Przetwarzanie i czyszczenie danych, identyfikacja brakujących wartości",
        "resume59": "Pozyskiwanie i procesowanie danych z różnych źródeł: .txt, .xlsx, .csv, .xml, .json",
        "resume60": "Transformacje danych, schematy ewaluacji (train-test, walidacja krzyżowa), ocena istotności zmiennych",
        "resume61": "Optymalizacja hiperparametrów, automatyzacja procesu modelowania (pipelines), walidacja modeli",
        "resume62": "Statystyczne metody analizy danych, estymacja i weryfikacja",
        "resume63": "Podstawowe sieci neuronowe (Deep learning), klasyfikacja obrazów i tekstów (Keras, TensorFlow)",
        "resume64": "Python for Data Science and Machine Learning",
        "resume65": "Kurs online, 25 godz.",
        "resume66": "Python: NumPy, Pandas, Matplotlib, Scikit-learn",
        "resume67": "Jupyter Notebook (Linux), PyCharm",
        "resume68": "Metody uczenia maszynowego: regresja liniowa i logistyczna, drzewa decyzyjne i lasy losowe",
        "resume69": "Python dla początkujących",
        "resume70": "Kurs online, 25 godz.",
        "resume71": "Python: pętle, instrukcje warunkowe, funkcje",
        "resume72": "IDLE, PyCharm",
        "resume73": "Awans Kompetencyjny",
        "resume74": "Uniwersytet im. Adama Mickiewicza <span>&#124;</span> Poznań",
        "resume75": "Staż stacjonarny, 3 miesiące",
        "resume76": "Innowacyjne kompetencje geografa na współczesnym rynku pracy: wysokiej jakości program stażowy dla studentów nauk o Ziemi na&nbsp;Wydziale Nauk Geograficznych i Geodezyjnych na Uniwersytecie im.&nbsp;Adama Mickiewicza w Poznaniu.",
        "resume77": "Wykształcenie",
        "resume78": "Geoinformacja <span>&#124;</span> Inżynier",
        "resume79": "<span class=\"underline\">Temat pracy inżynierskiej:</span> „Aplikacja mapowa z funkcjonalnością geokwestionariusza &ndash; szablon portalu geoinformacyjnego”",
        "resume80": "Aplikacja internetowa będąca kreatorem portalu geoinformacyjnego umożliwiająca stworzenie dowolnej ankiety w oparciu o dane przestrzenne z podkładem mapowym.&#10;(Technologie: HTML, CSS, JavaScript, PHP)",
        "resume81": "Uczenie maszynowe i modelowanie danych",
        "resume82": "Wizualizacja danych z biblioteką Matplotlib i Seaborn",
        "resume83": "Wykorzystywanie metod uczenia maszynowego oraz technik modelowania: szeregi czasowe, regresja liniowa i logistyczna, SVM, drzewa decyzyjne, lasy losowe, PCA, analiza skupień, algorytm XGBoost (Scikit-learn)",
        "resume84": "Wykrywanie anomalii w danych",
        "resume85": "Zastosowanie w analizie biznesowej",
        "resume86": "Analiza trendów i predykcja na podstawie danych historycznych",
        "resume87": "Algorytmy grupowania danych (segmentacji klientów) – dobór algorytmu do problemu, analiza i interpretacja efektów",
        "resume88": "Tworzenie raportów z przeprowadzonych analiz",
        "resume89": "Bazy danych i SQL",
        "resume90": "Pobieranie i przetwarzanie danych z baz SQL", 
        "resume91": "Tworzenie zapytań i optymalizacja operacji na dużych zbiorach danych",
        "resume92": "System wersjonowania kodu Git",
        "resume93": "Projekt końcowy",
        "resume94": "Opracowanie modelu predykcyjnego dla rzeczywistego problemu biznesowego",
        "resume95": "Prezentacja wyników i rekomendacji", 
        "skill1": "Umiejętności",
        "skill2": "„Bardzo wierzę w szczęście i uważam, że im ciężej pracuję, tym więcej go mam.”",
        "skill3": "Znajomość języków",
        "skill4": "Kliknij tutaj",
        "skill5": "Języki obce",
        "skill6": "Polski (ojczysty), Angielski (B2)",
        "skill7": "Bazy danych",
        "skill8": "Kontrola wersji",
        "skill9": "Biblioteki uczenia maszynowego",
        "skill10": "Eksploracja danych",
        "skill11": "Pozyskiwanie i procesowanie danych, czyszczenie danych, wizualizacja danych, analiza jednoczynnikowa&#10;i dwuwymiarowa, wykrywanie wartości odstających, testowanie statystyczne",
        "skill12": "Metody i techniki modelowania",
        "skill13": "Regresja liniowa i logistyczna, SVM, drzewa decyzyjne,&#10;lasy losowe, algorytm XGBoost, analiza skupień",
        "skill14": "Modelowanie",
        "skill15": "Transformacje danych, schematy ewaluacji, optymalizacja hiperparametrów, automatyzacja procesu modelowania (pipelines), walidacja modeli",
        "skill16": "Oprogramowanie",
        "skill17": "Data Science &#10;&#38; Analysis",
        "skill18": "Geograficzne / GIS",
        "skill19": "Teledetekcja&#10;i&nbsp;Fotogrametria",
        "skill20": "Trimble Inpho, TerraSolid, Agisoft Metashape,&#10;Riegl Software, Inertial Explorer, iX Capture,&#10;CATALYST od PCI Geomatics",
        "skill21": "Graficzne i kreatywne",
        "skill22": "Umiejętności miękkie",
        "skill23": "Komunikacja",
        "skill24": "Płynnie komunikuję się (w formie pisemnej i ustnej) ze współpracownikami i klientami",
        "skill25": "Rozwiązywanie problemów",
        "skill26": "Potrafię spokojnie przeanalizować sytuację i zidentyfikować możliwe rozwiązania",
        "skill27": "Zarządzanie czasem",
        "skill28": "Potrafię efektywnie zarządzać wieloma zadaniami jednocześnie",
        "skill29": "Odpowiedzialność",
        "skill30": "Jestem świadomy konsekwencji swoich decyzji",
        "skill31": "Praca zespołowa",
        "skill32": "Posiadam łatwość współpracy z innymi, aby osiągnąć wspólny cel",
        "skill33": "Elastyczność",
        "skill34": "Potrafię dostosować się do zmieniających się potrzeb projektowych",
        "skill35": "Samodzielność",
        "skill36": "Samodzielnie wykonuję powierzone mi zadania",
        "skill37": "Przywództwo",
        "skill38": "Potrafię rozwiązywać konflikty, monitorować postępy i utrzymać harmonię w grupie",
        "skill39": "Pewność siebie",
        "skill40": "Jestem pewny swoich umiejętności zawodowych, swobodnie wyrażam swoje opinie",
        "skill41": "Rzetelność",
        "skill42": "Skrupulatnie i dokładnnie wykonuje obowiązki",
        "skill43": "Podstawowe programy",
        "skill44": "Systemy opracyjne",
        "skill45": "Komunikacja",
        "skill46": "Współpraca",
        "skill47": "assets/images/skills-circle_newPL.png",
        "skill48": "Power BI (poziom podstawowy), Excel (poziom zaawansowany),",
        "portfolio1": "Portfolio",
        "portfolio2": "„Jeśli kochasz to co robisz i sprawia Ci to radość, cała ciężka praca&#10;i wytrwałość się opłacią.”",
        "portfolio3": "Filtruj:",
        "portfolio4": "Wszystkie<span class=\"category-count\">11</span>",
        "portfolio5": "Projekty GIS<span class=\"category-count\">1</span>",
        "portfolio6": "Projekty graficzne<span class=\"category-count\">3</span>",
        "portfolio7": "Projekty GIS, Front-End",
        "portfolio8": "Narzędzie partycypacji społecznej &ndash; geoankieta",
        "portfolio9": "OTWÓRZ",
        "portfolio10": "Klasyfikacja kotów i psów z użyciem CNN Keras",
        "portfolio11": "Rozpoznanie cukrzycy i ocena czynników ryzyka",
        "portfolio12": "Prognozowanie cen domów jednorodzinnych",
        "portfolio13": "Katastrofa Tytanika",
        "portfolio14": "Własna strona &ndash; CV",
        "portfolio15": "Pobieranie danych ze stron WWW",
        "portfolio16": "Generator haseł",
        "portfolio17": "Projekty graficzne",
        "portfolio18": "Zaproszenia ślubne",
        "portfolio19": "Logo i wizytówki",
        "contact1": "Kontakt",
        "contact2": "Kto mówi &ndash; sieje, kto słucha &ndash; zbiera.",
        "contact3": "Skontaktuj się ze mną telefonicznie lub poprzez formularz poniżej",
        "contact4": "Zadzwoń do mnie",
        "contact5": "Napisz do mnie",
        "contact6": "Adres",
        "contact7": "Kraków, Polska",
        "contact8": "Twoje Imię*",
        "contact9": "Twój adres E-mail*",
        "contact10": "Twój numer telefonu",
        "contact11": "Tytuł wiadomości*",
        "contact12": "Treść wiadomości*",
        "contact13": "Wyślij wiadomość",
        "contact14": "Pole oznaczone * są wymagane",
        "footer1": "Zaprojektowane przez &copy;&nbsp;",
        "model_all1": "Szczegóły projektu",
        "model_all2": "Kategoria:",
        "model_all3": "Projekty GIS, Front-End web development",
        "model_all4": "Data:",
        "model_all5": "Design:",
        "model_all6": "Technologia",
        "model_all7": "Zobacz projekt",
        "model_all8": "Opis projektu",
        "model_all9": "Dane z:",
        "model_all10": "Projekty graficzne",
        "model1_1": "Narzędzie partycypacji społecznej &ndash; geoankieta",
        "model1_2": "Luty 2016",
        "model1_3": "Prezentowany projekt to moja praca inżynierska pod tytułem „Aplikacja mapowa z funkcjonalnością geo-kwestionariusza &ndash; szablon portalu geoinformacyjnego”.",
        "model1_4": "Jest to aplikacja internetowa będąca kreatorem portalu geoinformacyjnego umożliwiająca stworzenie dowolnej ankiety w oparciu o dane przestrzenne z podkładem mapowym. Została ona wykorzystana w projekcie naukowym finansowanym przez Narodowe Centrum Nauki pod tytułem „Partycypacyjny paradygmat planowania przestrzennego &ndash; identyfikacja stanu oraz budowa modelu partycypacji w planowaniu przestrzennym w polskim dużym mieście” o numerze: 2014/15/B/HS4/00839 kierowanym przez prof. dr hab Jacka Kotusa.",
        "model1_5": "<span>Generator geoankiety</span>",
        "model1_6": "Jest to dashboard dla administratora geoankiety. Pozwala stworzyć geoankietę na dowolny temat, w której kluczowym jest zebranie informacji przestrzennej od ankietowanych. Generator pozwala na ustawienie tytułu samej ankiety oraz umożliwia utworzenie tekstu powitalnego i podziękowania za udział w ankiecie. W czwartym kroku administator ma możliwość określenia ile pytań będzie w geoankiecie oraz jakiego typu będzie do nich odpowiedź. Osoba biorąca udział w badaniu będzie miała możliwość udzielenia odpowiedzi na zadanie pytanie poprzez zaznaczenie konkretnej lokalizacji przy użyciu punktu, linii łamanej lub poligonu. Aby korespondent mógł odróżnić zaznaczenia na mapie, administrator może ustawić różny kolor dla poszczególnych pytań i odpowiedzi. Koleją opcją jest wybranie podkładu mapowego jaki będzie wyświetlał się w geoankiecie oraz przybliżenia startowego, co pozwoli zawęzić obszar na mapie, w którym możliwe będzie udzielenie odpowiedzi.",
        "model1_7": "Po kliknięciu w przycisk <span>GENERUJ GEOANKIETĘ</span>, administrator otrzymuje informacje czy wszystkie dane zostały prawidłowo wypełnione oraz odnośnik do gotowej geoankiety.",
        "model1_8": "Cały generator jest połączony z bazą SQL, w której zapisywane są wszystkie ustawienia administratora.",
        "model1_9": "<span>Panel logowania</span>",
        "model1_10": "Administrator ma możliwość utworzenia dowolnej liczby kont, które będą miały dostęp do pytań zawartych w geoankiecie. Konta należy utworzyć bezpośrednio w dedykowanej bazie danych SQL. Każdy ankietowany przed przystąpieniem będzie musiał najpierw prowadzić dane do logowania.",
        "model1_11": "Dzięki temu rozwiązaniu administrator geoankiety ma możliwość sprawdzenia odpowiedzi danej osoby.",
        "model1_12": "Jeśli projektankt geoankiety uzna, że odpowiedzi na pytania mają być anonimowe, ma możliwość zrezygnowania z panelu logowania.",
        "model1_13": "<span>Panel powitalny</span>",
        "model1_14": "To panel rozpoczynający uczestnictwo w geoankiecie. Korespondent zostaje wprowadzony w tematykę badania w jakim bierze ucział. Tekst powitalny został przygotowany na etapie generowania geoankiety przez administratowa.",
        "model1_15": "Po kliknięciu w przcisk <span>Rozpocznij badanie</span>, korespondent zostanie przesiony do przygotowanych pytań. W prawym górnym rogu mamy informację jaka osoba jest zalogowana do geoankiety. Istnieje również możliwość zrezygnowania z udziału poprzez wylogowanie się.",
        "model1_16": "<span>Geoankieta &ndash; odpowiadanie na pytania</span>",
        "model1_17": "Panele z pokładem mapowym to kluczowe elementy geoankiety. To właśnie tutaj jest możliwość odpowiadania na przygotowane pytania. Liczba etapów generowana jest automatycznie oraz jest zależna od liczby przygotowanych pytań. Każdy etap zkłąda się z maksymalnie 2 pytań, aby zaznaczenia na mapie były przejrzyste dla korespondenta.",
        "model1_18": "Po udzieleniu odpowiedzi poprzez zaznaczenie punktu lub narysowanie lini czy obszaru, osoba ma możliwość przejścia dalej aby kontunuować badanie. W każdym momencie może wrócić do porzedniego etapu i zmienić odpowiedź.",
        "model1_19": "<span>Panel końcowy</span>",
        "model1_20": "Panel końcowy to ostatni element geoankiety, w którym użytkownik otrzymuje podziękowanie za udział w przygotowanym badaniu. Tekst tego podziękowania jest możliwy do personalizacji na etapie generatora geoankiety.",
        "model1_21": "Po kliknięciu w przycisk <span>Wyloguj się i zakończ badanie</span>, udzielone odpowiedzi zostają zatwierdzone i przesłane do bazy danych SQL wraz z oznaczeniem, który użytkownik ich udzielił.",
        "model2_1": "Klasyfikacja kotów i psów z użyciem CNN Keras",
        "model2_2": "Maj 2024",
        "model2_3": "Rozpoznanie i nazwanie zwierzęcia lub przedmiotu nie stanowi dla człowieka większego problemu. Jednak czy dla komputera będzie to równie proste, dysponując jedynie zdjęciem czworonoga? Jako, że interesuję się uczeniem maszynowym, nie mogłem przejść obok takiego pytania obojętnie. Postanowiłem sprawdzić czy oraz z jaką skutecznością komputer będzie w stanie rozpoznać gatunek zwięrzęcia przedstawiony na zdjęciu.",
        "model2_4": "Klasyfikacja psów i kotów to jeden ze standardowych projektów głębokiego uczenia z zakresu widzenia komputerowego, który obejmuje klasyfikację realistycznych zdjęć na dwie kategorie. W trakcie realizacji projektu musiałem najpierw załadować i przygotować obrazy do celów treningowych, a następnie rozdzielić zdjęcia na zbiór danych do celu szkolenia i walidacji. Kolejno, użyłem ImageDataGenerator, aby rozszerzyć swój zbiór danych i ograniczyć nadmierne dopasowanie. Opracowałem model CNN za pomocą biblioteki KERAS i wybrałem parametry aby poprawić jego wydajność. W następnym kroku oceniłem wydajność modelu, zapisałem i załadowałem model do dalszych prognoz, a na koniec dokonałem klasyfikacji na zwierzętach będących w mojej rodzinie.",
        "model2_5": "Do realizacji projektu wykorzystałem zbiór danych obejmujący łącznie 25000 zdjęć przedstawiających psy i koty. Ten zbiór danych został po raz pierwszy wprowadzony na potrzeby konkursu Kaggle w 2013 roku.",
        "model2_6": "Zbiór danych jest dostępny <a href=\"https://www.kaggle.com/datasets/shaunthesheep/microsoft-catsvsdogs-dataset/data/\" target=\"_blank\" rel=\"noopener noreferrer\">tutaj</a> (około 865 MB).",
        "model2_7": "Aby dokonać klasyfikacji obrazów na dwie kategorie: psy i koty, zastosowałem do tego konwolucyjną sieć neuronową (CNN &ndash; convolutional neural network).",
        "model2_8": "Architektura modelu:",
        "model2_9": "Warstwy:",
        "model2_10": "Warstwa wejściowa składa się z warstwy Conv2D z 32 filtrami i funkcją aktywacji ReLU.",
        "model2_11": "Model zawiera 3 bloki konwolucyjne z rosnącymi liczbą filtrów i aktywacją ReLU.",
        "model2_12": "Każdy blok konwolucyjny zawiera normalizację wsadową (Batch Normalization), maksymalne próbkowanie (Max Pooling) (rozmiar siatki &#61; 2) i warstwę Dropout (0,2).",
        "model2_13": "Warstwy w pełni połączone zawierają warstwę spłaszczającą (Flatten), warstwę Dense z 512 jednostkami i warstwę Dropout.",
        "model2_14": "Warstwa wyjściowa to warstwa Dense z 2 jednostkami i aktywacją softmax.",
        "model2_15": "Komponenty:",
        "model2_16": "Warstwa wejściowa: Odbiera obrazy wejściowe do klasyfikacji.",
        "model2_17": "Warstwy splotowe: Wyodrębniają cechy z obrazów za pomocą operacji konwolucyjnych.",
        "model2_18": "Warstwy próbkowania: Zmniejszają przestrzenne wymiary obiektów.",
        "model2_19": "Warstwa spłaszczająca: Przekształca mapy obiektów 2D na wektor 1D.",
        "model2_20": "Warstwy w pełni połączone: Wykonują klasyfikację za pomocą gęsto połączonych warstw.",
        "model2_21": "Warstwa wyjściowa: Dostarcza końcowe prawdopodobieństwa predykcji dla klas kota i psa.",
        "model2_22": "Z sukcesem zbudowałem model głębokiej sieci neuronowej poprzez wdrożenie konwolucyjnej sieci neuronowej (CNN), który uzyskał ponad 6,8 mln parametrów uczących się. Przełożyło się to na uzyskanie bardzo dużej dokładności zaklasyfikowania obrazów na poziomie <span>około 94%</span> zarówno dla psów i kotów.",
        "model2_23": "Po nauczeniu i walidacji modelu przyszedł czas na odpowiedź czy moje zwierzęta to odpowiednio psy i koty. Ostatecznie komputer potwierdził moje zdanie. <span>Pełen sukces.</span>",
        "model3_1": "Rozpoznanie cukrzycy i ocena czynników ryzyka",
        "model3_2": "Wrzesień 2022",
        "model3_3": "Wprowadzenie do problematyki projektu:",
        "model3_4": "Cukrzyca jest jedną z najczęściej występujących chorób przewlekłych w Stanach Zjednoczonych, dotykając każdego roku miliony Amerykanów i stanowiąc znaczące obciążenie finansowe dla gospodarki. Cukrzyca to poważna choroba przewlekła, która może prowadzić do obniżenia jakości życia oraz skrócenia oczekiwanej długości życia. Skala tego problemu jest również istotna. Według danych Centers for Disease Control and Prevention (CDC) w 2018 roku 34,2 miliona Amerykanów miało cukrzycę, a 88 milionów miało stan przedcukrzycowy. Co więcej, CDC szacuje, że 1 na 5 chorych na cukrzycę i około 8 na 10 osób z prediabetes (stanem przedcukrzycowym) nie jest świadomych swojego ryzyka.",
        "model3_5": "Chociaż cukrzycy nie da się wyleczyć całkowicie, strategie takie jak utrata wagi, zdrowe odżywianie, aktywność fizyczna oraz leczenie farmakologiczne mogą złagodzić skutki tej choroby u wielu pacjentów. Wczesna diagnoza może prowadzić do zmian stylu życia i skuteczniejszego leczenia, co sprawia, że modele predykcyjne oceny ryzyka cukrzycy są ważnym narzędziem dla lekarzy i urzędników zdrowia publicznego.",
        "model3_6": "Opis zbioru danych użytego w projekcie:",
        "model3_7": "System Monitorowania Czynników Ryzyka Zachowań Zdrowotnych (BRFSS) to coroczna ankieta telefoniczna dotycząca zdrowia, zbierana przez CDC. Każdego roku ankieta gromadzi odpowiedzi od ponad 400 000 Amerykanów we wszystkich 50 stanach na temat ryzykownych zachowań zdrowotnych, przewlekłych schorzeń oraz korzystania z usług profilaktycznych. BRFSS jest prowadzony nieprzerwanie od 1984 roku, co czyni go największym nieprzerwanie prowadzonym systemem ankiet zdrowotnych na świecie.",
        "model3_8": "W ramach tego projektu użyto pliku w formacie SAS z danymi dostępnymi na stronie CDC dla roku 2019. Oryginalny zbiór danych zawiera odpowiedzi od 418268 osób i składa się z 342 cech. Te cechy to pytania bezpośrednio zadawane uczestnikom lub zmienne obliczone na podstawie indywidualnych odpowiedzi uczestników.<a href=\"https://www.cdc.gov/brfss/annual_data/annual_2019.html\" target=\"_blank\" rel=\"noopener noreferrer\">Link do danych</a>",
        "model3_9": "Na potrzeby tej analizy tylko spośród wszystkich cech uwzględnione zostały tylko te czynniki, które są związane z czynnikami ryzyka cukrzycy. W wyborze odpowiednich cech bardzo pomocna była praca badawcza autorstwa Zidian Xie pt. „Building Risk Prediction Models for Type 2 Diabetes Using Machine Learning Techniques” z 2014 roku.",
        "model3_10": "Cel projektu:",
        "model3_11": "Głównym celem tego projektu jest odpowiedź na pytanie:",
        "model3_12": "Czy pytania z ankiety BRFSS mogą dostarczyć dokładnych przewidywań dotyczących tego, czy dana osoba choruje na cukrzycę?",
        "model3_13": "Wyniki:",
        "model3_14": "Najlepszy wynik dla każdej metryki został osiągnięty przez <span>XGBoostClassifier</span> wyuczony na nadpróbkowanym zbiorze danych.",
        "model3_15": "<span>Dokładność (Accuracy):</span> Wynik <span class=\"number\">91,8%</span> na zbiorze testowym &ndash; to bardzo dobry rezultat. Model błędnie sklasyfikował jedynie 8% przypadków spośród wszystkich klasyfikacji.",
        "model3_16": "<span>F1-score:</span> Wynik <span class=\"number\">92%</span> - pokazuje, jak dokładnie model klasyfikuje przykłady jako „pozytywne” lub „negatywne”, w naszym przypadku jako osoby zdrowe lub osoby z cukrzycą.",
        "model3_17": "<span>AUC (Area Under the Curve):</span> AUC mierzy zdolność klasyfikatora do rozróżniania między klasami i jest używana jako podsumowanie krzywej ROC. Im wyższe AUC, tym lepsza wydajność modelu w rozróżnianiu między klasami pozytywnymi i negatywnymi. Wynik 0,917 jest bardzo dobrym wynikiem — <span class=\"number\">prawie 92%</span> przypadków model prawidłowo rozróżnia klasy pozytywne i negatywne.",
        "model3_18": "<span>Czułość (Recall):</span> Wynik <span class=\"number\">prawie 96,7%</span> jest bardzo dobry. Tylko w 3 przypadkach na 100 model błędnie klasyfikuje osobę jako chorą. Model wydaje się być bardzo skuteczny w warunkach klinicznych, szczególnie dlatego, że wszystkie cechy są miarami nieinwazyjnymi.",
        "model3_19": "<span>Precyzja (Precision):</span> Wartość precyzji <span class=\"number\">prawie 88%</span> mówi nam, jak pewni możemy być, że dana osoba rzeczywiście cierpi na chorobę. Pokazuje to, jak dobrze test odróżnia osoby cierpiące na chorobę od osób, które jej nie mają. Prawie w 9/10 przypadków możemy być pewni, że model poprawnie przewiduje cukrzycę u osoby, która faktycznie na nią choruje.",
        "model3_20": "Zdięcie wykonane przez<a href=\"https://www.freepik.com/author/macrovector\">macrovector</a>z Freepik.",
        "model4_1": "Prognozowanie cen domów jednorodzinnych",
        "model4_2": "Wrzesień 2022",
        "model4_3": "Projekt, którego celem było prognozowanie cen domów to idealny konkurs dla osób zajmujących się nauką o danych, którze chcą poszerzyć swoje umiejętności z zakresu uczenia maszynowego. Dlatego i ja postanowiłem przystąpić tego projektu z www.kaggle.com.<a href=\"https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data\" target=\"_blank\" rel=\"noopener noreferrer\">Link do danych</a>",
        "model4_4": "Opis danych użytych w projekcie:",
        "model4_5": "Zbiór danych zawiera 79 różnych zmiennych opisujących (prawie) każdy aspekt domów mieszkalnych w Ames w stanie Iowa, m.in.:",
        "model4_6": "Powierzchnia działki, na której stoi dom",
        "model4_7": "Czy jest dostęp do alei lub drogi oraz jak dużo dróg jest w pobliżu nieruchomości",
        "model4_8": "Typ zabudowy oraz styl budownictwa i wykończenia",
        "model4_9": "Rodzaj zastosowanego ogrzewania i jego jakość i stan techniczny",
        "model4_10": "Jakie media są dostępne",
        "model4_11": "Liczba sypialni, łazienek czy kuchni oraz ich jakość",
        "model4_12": "Powierzchnia basenu i wiele innych",
        "model4_13": "Celem ćwieczenia było rozwinięcie umiejętności w budowie kreatywnych funkcji oraz przede wszystkim zapoznanie się z zaawansowanymi technikami regresji. Finalnie przy wykorzystaniu najlepszego modelu przewidzieć cenę domu mieszkalnego.",
        "model4_14": "Opracowałem wiele modeli regresji, zarówno ich podstawowe wersje oraz wersje z wyszukanymi hiperparametrami. Najlepszym modelem okazał się <span>ElasticNet z hiperparametrami</span>, który uzyskał RMSE na poziomie <span>0.1169</span> oraz R-Squered na poziomie <span>0.915.</span>",
        "model4_15": "Zdięcie wykonane przez<a href=\"https://pl.freepik.com/autor/freepik\">freepik</a>z Freepik.",
        "model5_1": "Katastrofa Tytanika",
        "model5_2": "Wrzesień 2022",
        "model5_3": "Zarys historyczny:",
        "model5_4": "Historia katastrowy Tytanika jest chyba wszystkim znana. Był to luksusowym brytyjski liniowiec, który zatonął podczas swojego dziewiczego rejsu z Southampton do Nowego Jorku w 1912 roku. Był to największy statek pasażerski w tamtych czasach, a jego konstrukcja była uważana za cud techniki, co sprawiło, że wielu ludzi wierzyło, iż jest „niezatapialny”.",
        "model5_5": "Titanic wyruszył z ponad 2200 pasażerami i członkami załogi na pokładzie. Wśród pasażerów znajdowały się osoby różnych klas społecznych, od najbogatszych ludzi tamtych czasów po emigrantów szukających lepszego życia w Ameryce.",
        "model5_6": "W nocy 14 kwietnia 1912 roku Titanic zderzył się z górą lodową na północnym Atlantyku. W wyniku kolizji statek doznał poważnych uszkodzeń i zaczął tonąć. Katastrofa pochłonęła życie ponad 1500 osób, co uczyniło ją jedną z największych tragedii morskich w historii. Tylko około 700 osób przeżyło, głównie dzięki szalupom ratunkowym.",
        "model5_7": "Katastrofa Titanica stała się tematem wielu badań, również w analizie danych czy machine learningu.",
        "model5_8": "Opis danych użytych w projekcie:",
        "model5_9": "Ten projekt jest związany z konkursem „Titanic: Machine Learning from Disaster” na platformie Kaggle. Jest jednym z najpopularniejszych i najczęściej polecanych projektów dla początkujących data scientistów i analityków danych. W ramach tego konkursu uczestnicy mają za zadanie przewidzieć, którzy pasażerowie Titanica przeżyli katastrofę, a którzy niestety nie, na podstawie dostarczonych danych. Zbiór danych użyty w projekcie zawiera 10 zmiennych, które powinny pomóc osiągnąc cel.<a href=\"https://www.kaggle.com/competitions/titanic/data\" target=\"_blank\" rel=\"noopener noreferrer\">Link do danych</a>",
        "model5_10": "Kluczowe Cechy Zbioru Danych:",
        "model5_11": "Pclass (klasa podróży): 1, 2 lub 3.",
        "model5_12": "Name (imię i nazwisko): Może zawierać tytuły, które mogą być użyteczne.",
        "model5_13": "Sex (płeć): Ważny czynnik przy przewidywaniu przetrwania.",
        "model5_14": "Age (wiek): Wartości w niektórych wierszach są brakujące i wymagają uzupełnienia.",
        "model5_15": "SibSp (liczba rodzeństwa i małżonków na pokładzie).",
        "model5_16": "Parch (liczba rodziców i dzieci na pokładzie).",
        "model5_17": "Ticket (bilet): Może zawierać informacje o grupach podróżnych.",
        "model5_18": "Fare (opłata za bilet): Może wskazywać na status ekonomiczny.",
        "model5_19": "Cabin (kabina): Wiele brakujących wartości, ale może być użyteczna.",
        "model5_20": "Embarked (port zaokrętowania): C, Q, S.",
        "model5_21": "Wyniki:",
        "model5_22": "Po dogłębnym przeanalizowaniu wszystkich zmiennych oraz po wyczyszczeniu danych przystąpiłem do budowania modeli klasyfikacyjnych. W moim przypadku najlepszym modelem okazał się VotingClassifier. Model osiągnął wynik cross-validacji na poziomie <span>około 83.6 %</span>.",
        "model5_23": "Zdięcie wykonane przez<a href=\"https://pl.freepik.com/autor/vectorpouch\">vectorpouch</a>z Freepik.",
        "model6_1": "Własna strona &ndash; CV",
        "model6_2": "Stale aktualizowana",
        "model6_3": "Pomysł utworzenia własnej strony internetowej w stylu portfolio narodził się już dawno temu. Impulsem do działania była m.in. chęć podzielenia się z innymi osobami samodzielnie zrealizowanymi projektami z różnych kategorii. Z uwagi na to, że ciężko jest przedstawić swoje dokonania na kartce papieru w formacie A4, postanowiłem zbudować tę stronę. Jest ona swego rodzaju rozbudowanym interaktywnym życiorysem, w którym umieściłem informacje o sobie, zdobytym doświadczeniu zawodowym i wykształceniu, a także projekty wraz z odnośnikami do ich kodu źródłowego.",
        "model6_4": "Strona jest responsywna. Starałem się przygotować ją tak aby prawidłowo uruchamiała się na każdym urządzeniu. Planuję stale aktualizować wszystkie informacje jakie się tutaj znajdują oraz dodawać nowe projekty, zarówno ukończone jak i w trakcie realizacji.",
        "model6_5": "Niedawno na stronie pojawiła się nowa funkcjonalność, mianowicie możliwość uruchomienia strony w wersji w języku angielskim. W przyszłości możliwe, że pojawi się nowa pozycja w menu &ndash; <span>Blog</span>, w którym będę umieszczał ciekawe nowinki z branży GIS oraz Data Science czy też popularnego teraz AI.",
        "model6_6": "Jeśli chcesz się ze mną skontaktować zapraszam do sekcji <span>Kontakt</span>.",
        "model7_1": "Pobieranie danych ze stron WWW &ndash; Web scraping",
        "model7_2": "Marzec 2022",
        "model7_3": "Projekt realizowany w ramach utrwalania wiedzy zdobytej w trakcie Bootcampu Data Science PRO. Jest to mały projekt typu web scraping, którego głównym celem było automatyczne pobranie danych przy użyciu języka python oraz biblioteki BeautifulSoup.",
        "model7_4": "Z uwagi na moje zainteresowanie dbaniem o własne finanse osobiste oraz inwestowaniem w różne aktywa, w tym kryptowaluty, za cel obrałem stronę internetową &ndash; <a href=\"https://crypto.com/price/pl\" target=\"_blank\" rel=\"noopener noreferrer\">www.crypto.com</a>, która zawiera aktualny kurs wszystkich kryprowalut.",
        "model7_5": "Projekt zakładał pobranie danych ze strony dla 500 pierwszych coinów oraz zapisanie ich do arkusza kalkulacyjnego Excel.",
        "model7_6": "Zdięcie wykonane przez<a href=\"https://pl.freepik.com/autor/freepik\">freepik</a>z Freepik.",
        "model8_1": "Generator haseł",
        "model8_2": "Kwiecień 2022",
        "model8_3": "Generator haseł to jeden z podstawowych projektów, jakie robi się podczas nauki programowania przeróżnych języków. Tak też było w moim przypadku w czasie nauki Pythona.",
        "model8_4": "Aplikacja zakładała, że użytkownik poda kilka informacji:",
        "model8_5": "Dla jakiej strony/aplikacji zamierza utworzyć hasło",
        "model8_6": "Jakią nazwę użytkownika przypisuje do tego hasła",
        "model8_7": "Jaką minimalną długość ma mieć wygenerowane hasło",
        "model8_8": "Czy w haśle mają znajdować się liczby",
        "model8_9": "Czy w haśle mają znajdować się znaki specjalne",
        "model8_10": "Wygenerowane hasła trafiają do pliku. W przyszłości istnieje możliwość rozbudowania tej opcji zastępując zwykły plik TXT np. bazą danych chronioną hasłem.",
        "model8_11": "Nie chciałem aby ten generator był klasycznym projektem jakich wiele. Dlatego postanowiłem utworzyć tez w pythonie do niego proste GUI.",
        "model8_12": "Zdięcie wykonane przez<a href=\"https://pl.freepik.com/autor/freepik\">freepik</a>z Freepik.",
        "model9_1": "Zaproszenia ślubne",
        "model9_2": "Czerwiec 2024",
        "model9_3": "Realizowanie projektów graficznych sprawia mi przyjemność, zwłaszcza jeśli mogę w ten sposób pomóc przyjaciołom. Tak też było w tym przypadku. Projekt dotyczył zaprojektowania zaproszeń ślubnych w formacie A5 wraz z winietkami jakie miały znaleźć się na stołach oraz etykietami na upominki od pary młodej dla gości.",
        "model9_4": "Zaproszenia miały być w tematyce leśnej, bo w takiej scenerii odbywał się również ślub oraz przyjęcie.",
        "model9_5": "Źródła szaty graficznej:",
        "model9_6": "Tło użyte w projekcie &ndash; pastelowy las:",
        "model9_7": "Autor: <a href=\"https://pl.freepik.com/autor/pickoloh\" target=\"_blank\" rel=\"noopener noreferrer\"> pickoloh </a> | Portal: <a href=\"https://www.freepik.com\" target=\"_blank\" rel=\"noopener noreferrer\"> www.freepik.com</a>",
        "model9_8": "Ikony użyte w projekcie:",
        "model9_9": "Autor: Mateusz Wuchnicki",
        "model9_10": "Czcionka użyta w projekcie:",
        "model10_1": "Zaproszenia ślubne",
        "model10_2": "Czerwiec 2024",
        "model10_3": "Realizowanie projektów stricte graficznych sprawia mi przyjemność, zwłaszcza jeśli mogę w ten sposób pomóc przyjaciołom. Tak też było w tym przypadku. Projekt dotyczył zaprojektowania zaproszeń ślubnych w formacie A5 wraz z winietkami jakie miały być znaleźć się na stołach.",
        "model10_4": "Zaproszenia miały być w tematyce kwiatów z przeważającym kolorem różowym.",
        "model10_5": "Źródła szaty graficznej:",
        "model10_6": "Tło użyte w projekcie &ndash; ramka oraz kwiaty:",
        "model10_7": "Autor: <a href=\"https://it.freepik.com/autore/dede-sumiarsih\" target=\"_blank\" rel=\"noopener noreferrer\">dede-sumiarsih</a> | Portal: <a href=\"https://www.freepik.com\" target=\"_blank\" rel=\"noopener noreferrer\"> www.freepik.com</a>",
        "model10_8": "Ikony użyte w projekcie:",
        "model10_9": "Autor: Mateusz Wuchnicki",
        "model10_10": "Czcionka użyta w projekcie:",
        "model11_1": "Logo i wizytówki",
        "model11_2": "Październik 2018",
        "model11_3": "Projekt dotyczył stworzenie nowego Loga oraz wizytówek dla firmy świadczącej usługi geodezyjnej.",
        "model11_4": "Logotyp miał zawierać imię i nazwisko osoby prowadzącej jednoosobową działalność gospodarczą oraz jednoznacznie kojarzyć się z geodezją. Dlatego <span>litera A</span> przedstawia instrument geodezyjny &ndash; tachimetr, natomiast <span>litera I</span> została wykonana na wzrór łaty geodezyjnej."        
    },
    "EN": {
        "menu1": "HOME",
        "menu2": "ABOUT ME",
        "menu3": "RESUME",
        "menu4": "SKILLS",
        "menu5": "PORTFOLIO",
        "menu6": "CONTACT",
        "menu7": "Designed by &copy;&nbsp;",
        "home1": "Hello, I'm",
        "home2": "Mateusz Wuchnicki",
        "home3": "GIS Specialist, Data Analyst&#10;and enthusiast of Data Science and&nbsp;Machine&nbsp;Learning&#10;from Krakow, Poland",
        "home4": "DOWNLOAD CV",
        "home5": "Polish version",
        "home6": "English version",
        "about1": "Name and Surname ",
        "about2": "Birthday ",
        "about3": "February 1, 1994",
        "about4": "Email ",
        "about5": "Address ",
        "about6": "Krakow, Poland",
        "about7": "Phone ",
        "about8": "About Me",
        "about9": "Specialist in GIS, Photogrammetry&#10;and Remote Sensing",
        "about10": "I am a qualified engineer with 7&#43; years of experience. I&nbsp;have actively participated in numerous commercial and research-development projects. I&nbsp;have conducted many spatial analyses, developed orthophotomaps, terrain models, and point clouds from airborne laser scanning, as well as written technical reports. I&nbsp;have been responsible for planning, monitoring, and&nbsp;coordinating flight missions aimed at acquiring high-resolution aerial photos and ALS point clouds. I possess exceptional analytical, organizational, planning, and communication skills, along with a focused approach to working in a structured environment. I am seeking a job where I can utilize my skills and continue to grow within the broad GIS industry.",
        "about11": "Hobbies &#124; Interests",
        "about12": "Mountain Climbing",
        "about13": "Running",
        "about14": "Personal Finance&#10;&amp; Investing",
        "about15": "Data Science&#10;&amp; Analysis",
        "about16": "E-Sport",
        "resume1": "Resume",
        "resume2": "„Good decisions come from experience. Experience comes from making bad decisions.”",
        "resume3": "&ndash; Mark Twain",
        "resume4": "Work Experience",
        "resume5": "Technical Manager in the Aviation Technology Department",
        "resume6": "SmallGIS Sp. z o.o. <span>&#124;</span> Krakow",
        "resume7": "Within the company's internal structure, I served as a technical manager in the aviation technology department. I was responsible for the efficient operation and substantive support of the team of analysts and technical staff. At the same time, I performed the function of operational supervision of aviation missions.",
        "resume8": "My duties included:",
        "resume9": "Coordination of analytical and geospatial projects",
        "resume10": "Optimization of data processing and results reporting processes using Python",
        "resume11": "Analysis of large datasets and preparation of reports",
        "resume12": "Identification of risks and their impact on project execution",
        "resume13": "Preparation of reports and data visualizations for stakeholders",
        "resume14": "Organizing training for the technical team",
        "resume15": "Identifying potential risks associated with project implementation",
        "resume16": "Analysis and modeling of spatial data for business projects",
        "resume17": "GIS, Photogrammetry and Remote Sensing Analyst",
        "resume18": "While working in the aviation technology department, I gained extensive experience in data analysis and project management. I was responsible for planning, coordinating, and optimizing processes for acquiring and processing geospatial data.",
        "resume19": "Conducting geospatial analyses",
        "resume20": "Developing aerial orthophotos and LiDAR (ALS) data",
        "resume21": "Processing satellite and hyperspectral imagery",
        "resume22": "Comprehensive planning, monitoring, and coordination of aviation missions",
        "resume23": "Coordinating activities with various authorities and military units",
        "resume24": "Management of technical and operational documentation",
        "resume25": "Direct contact with clients",
        "resume26": "GIS Technician",
        "resume27": "I used GIS and analytical tools for processing and analyzing spatial data. I participated in projects related to spatial data and the implementation of analytical processes.",
        "resume28": "Developing aerial orthophotos and LiDAR data",
        "resume29": "Conducting spatial analyses",
        "resume30": "Processing vector and raster data",
        "resume31": "Conducting training in GIS analysis and software",
        "resume32": "Direct contact with clients",
        "resume33": "Intern",
        "resume34": "During my internship, I gained practical experience in data analysis and reporting. I participated in projects related to geospatial analysis and business process optimization.",
        "resume35": "Processing high-resolution aerial images and satellite imagery",
        "resume36": "Creating reports and reports on analyzes and projects",
        "resume37": "Processing and migrating data from various sources",
        "resume38": "Preparing technical documentation",
        "resume39": "Photogrammetry Technician",
        "resume40": "GEOCARTIS Sp. z o.o. Sp. K. <span>&#124;</span> Poznan",
        "resume41": "I specialized in creating 3D models and analyzing geospatial data. My work involved processing point clouds and optimizing analytical processes.",
        "resume42": "Creation of 3D models for business analysis",
        "resume43": "Development of data visualizations for commercial projects",
        "resume44": "Spatial data analysis and creation of detailed reports",
        "resume45": "Collaboration with analytical teams to optimize processes",
        "resume46": "GEOMAT Sp. z o.o. <span>&#124;</span> Poznan",
        "resume47": "A three-month internship in the geodesy industry, during which I learned tools for designing maps and databases. I improved my skills in using surveying instruments.",
        "resume48": "Updating the BDOT10k database and cartographic editing of the KARTO10k database",
        "resume49": "Controlling the attributes of GESUT database objects and creating thematic maps",
        "resume50": "Conducting geodetic measurements",
        "resume51": "Courses and Training",
        "resume52": "Sages, Kodołamacz <span>&#124;</span> Warsaw",
        "resume53": "Online course, 420 hours",
        "resume54": "Advanced Data Science and Data Analysis course, which included practical use of Python and analytical tools for data exploration, modeling, and visualization. The course was delivered in the form of intensive workshops with real-world case studies.",
        "resume55": "Course Scope and Acquired Skills:",
        "resume56": "Data Analysis and Programming in Python",
        "resume57": "Advanced data analysis using NumPy and Pandas",
        "resume58": "Data processing and cleaning, identification of missing values",
        "resume59": "Data acquisition and processing from various sources: .txt, .xlsx, .csv, .xml, .json",
        "resume60": "Data transformations, evaluation schemes (train-test, cross-validation), feature importance evaluation",
        "resume61": "Hyperparameter optimization, automation of the modeling process (pipelines), model validation",
        "resume62": "Statistical methods for data analysis, estimation, and verification",
        "resume63": "Basic neural networks (Deep learning), image and text classification (Keras, TensorFlow)",
        "resume64": "Python for Data Science and Machine Learning",
        "resume65": "Online course, 25 hours",
        "resume66": "Python: NumPy, Pandas, Matplotlib, Scikit-learn",
        "resume67": "Jupyter Notebook (Linux), PyCharm",
        "resume68": "Machine learning methods: linear and logistic regression, decision trees and random forests",
        "resume69": "Python for Beginners",
        "resume70": "Online course, 25 hours",
        "resume71": "Python: loops, conditional instructions, functions",
        "resume72": "IDLE, PyCharm",
        "resume73": "Awans Kompetencyjny&#10;internship-programme",
        "resume74": "Adam Mickiewicz University <span>&#124;</span> Poznan",
        "resume75": "On-site internship, 3 months",
        "resume76": "Innovative competencies of a geographer in the modern job market: a high-quality internship program for students of Earth Sciences at the Faculty of Geographical and Geological Sciences at Adam Mickiewicz University in Poznan.",
        "resume77": "Education",
        "resume78": "Geoinformation <span>&#124;</span> Bachelor of Science",
        "resume79": "<span class=\"underline\">Thesis topic:</span> „Map Application with Geo–Survey Functionality &ndash; Geoinformation Portal Template”",
        "resume80": "A web application serving as a creator of a geoinformation portal enabling the creation of any survey based on spatial data with a map background.&#10;(Technologies: HTML, CSS, JavaScript, PHP)",
        "resume81": "Machine Learning and Data Modeling",
        "resume82": "Data visualization with the Matplotlib and Seaborn libraries.",
        "resume83": "Machine learning methods and modeling techniques: time series, linear regression and logistic regression, SVM, decision trees, random forests, PCA, clustering analysis, XGBoost algorithm (Scikit-learn)",
        "resume84": "Anomaly detection in data",
        "resume85": "Application in business analysis",
        "resume86": "Trend analysis and prediction based on historical data",
        "resume87": "Data clustering algorithms (customer segmentation) – selecting the algorithm for the problem, analyzing and interpreting results",
        "resume88": "Preparing reports from conducted analyses",
        "resume89": "Databases and SQL",
        "resume90": "Data retrieval and processing from SQL databases",
        "resume91": "Query creation and optimization of operations on large datasets",
        "resume92": "Version control system Git",
        "resume93": "Final project",
        "resume94": "Development of a predictive model for a real business problem",
        "resume95": "Presentation of results and recommendations",
        "skill1": "Skills",
        "skill2": "„I am a great believer in luck, and I find the harder I work the more I have of it.”",
        "skill3": "Languages",
        "skill4": "Click here",
        "skill5": "Foreign Languages",
        "skill6": "Polish (native), English (B2)",
        "skill7": "Databases",
        "skill8": "Version Control",
        "skill9": "Machine Learning Libraries",
        "skill10": "Data Exploration",
        "skill11": "Data acquisition and processing, data cleaning, data visualization, one- and two-dimensional analysis (univariate and bivariate analysis), outlier detection, statistical testing",
        "skill12": "Modeling Methods and Techniques",
        "skill13": "Linear and logistic regression, SVM, decision trees, random forests, XGBoost algorithm, cluster analysis",
        "skill14": "Modeling",
        "skill15": "Data transformations, evaluation schemes, hyperparameter optimization, modeling process automation (pipelines), model validation",
        "skill16": "Software",
        "skill17": "Data Science &#10;&#38; Analysis",
        "skill18": "Geographic / GIS",
        "skill19": "Remote Sensing and&nbsp;Photogrammetry",
        "skill20": "Trimble Inpho, TerraSolid, Agisoft Metashape,&#10;Riegl Software, Inertial Explorer, iX Capture,&#10;CATALYST od PCI Geomatics",
        "skill21": "Graphic and Creative",
        "skill22": "Soft Skills",
        "skill23": "Communication",
        "skill24": "I communicate fluently (in writing and orally) with colleagues and clients",
        "skill25": "Problem Solving",
        "skill26": "I can calmly analyze a situation and identify possible solutions",
        "skill27": "Time Management",
        "skill28": "I am capable of managing multiple tasks simultaneously",
        "skill29": "Responsibility",
        "skill30": "I am aware of the consequences of my decisions",
        "skill31": "Teamwork",
        "skill32": "I easily collaborate with others to achieve a common goal",
        "skill33": "Flexibility",
        "skill34": "I can adapt to changing project needs",
        "skill35": "Independence",
        "skill36": "I independently complete assigned tasks",
        "skill37": "Leadership",
        "skill38": "I am able to resolve conflicts, monitor progress, and maintain harmony in a group",
        "skill39": "Self-confidence",
        "skill40": "I am confident in my professional skills and freely express my opinions",
        "skill41": "Reliability",
        "skill42": "I perform my duties scrupulously and precisely",
        "skill43": "Basic Programs",
        "skill44": "Operating Systems",
        "skill45": "Communication",
        "skill46": "Collaboration",
        "skill47": "assets/images/skills-circle_newEN.png",
        "skill48": "Power BI (basic), Excel (advanced),",
        "portfolio1": "Portfolio",
        "portfolio2": "„If you love what you do and it's making you happy, all the hard work&#10;and persistence will pay off.”",
        "portfolio3": "Filter:",
        "portfolio4": "All<span class=\"category-count\">11</span>",
        "portfolio5": "GIS Projects<span class=\"category-count\">1</span>",
        "portfolio6": "Graphic Projects<span class=\"category-count\">3</span>",
        "portfolio7": "GIS Projects, Front-End",
        "portfolio8": "Social participation tool &ndash; Geo–Survey",
        "portfolio9": "OPEN",
        "portfolio10": "Cats vs Dogs Classification using CNN Keras",
        "portfolio11": "Diabetes prediction and risk factors evaluation",
        "portfolio12": "Forecasting prices of single-family houses",
        "portfolio13": "Tytanic Disaster",
        "portfolio14": "Own website &ndash; RESUME",
        "portfolio15": "Web Scraping",
        "portfolio16": "Passwords Generator",
        "portfolio17": "Graphic Projects",
        "portfolio18": "Wedding invitation",
        "portfolio19": "Logo and business cards",
        "contact1": "Contact",
        "contact2": "Who speaks &ndash; sows, who listens &ndash; reaps.",
        "contact3": "Contact me by phone or via the form below",
        "contact4": "Call me",
        "contact5": "Write to me",
        "contact6": "Address",
        "contact7": "Krakow, Poland",
        "contact8": "Your Name*",
        "contact9": "Your E-mail*",
        "contact10": "Your phone number",
        "contact11": "Message title*",
        "contact12": "Message content*",
        "contact13": "Send message",
        "contact14": "Fields marked with * are required",
        "footer1": "Designed by &copy;&nbsp;",
        "model_all1": "Project Details",
        "model_all2": "Category:",
        "model_all3": "GIS Projects, Front-End Web Development",
        "model_all4": "Date:",
        "model_all5": "Design:",
        "model_all6": "Technology",
        "model_all7": "View Project",
        "model_all8": "Project Description",
        "model_all9": "Data from:",
        "model_all10": "Graphic projects",
        "model1_1": "Social participation tool &ndash; Geo–Survey",
        "model1_2": "February 2016",
        "model1_3": "The presented project is my engineering thesis titled „Map Application with Geo–Survey Functionality &ndash; Geoinformation Portal Template”.",
        "model1_4": "It is a web application that serves as a creator of geoinformation portals, enabling the creation of any survey based on spatial data with a map overlay. It was used in a scientific project funded by the National Science Center titled „Participatory spatial planning paradigm &ndash; the diagnossis of state and creating model of public participation in spatial planning of the Polish big city” with the number: 2014/15/B/HS4/00839, directed by Prof. Dr. Hab. Jacek.",
        "model1_5": "<span>Geo–Survey Generator</span>",
        "model1_6": "This is a dashboard for the Geo–Survey administrator. It allows the creation of a Geo–Survey on any topic, where the key aspect is gathering spatial information from respondents. The generator allows setting the title of the survey but also enables the creation of a welcome text and a thank you note for participating in the survey. In the fourth step, the administrator has the opportunity to determine how many questions will be in the Geo–Survey and what type of answers will be provided. The person taking part in the survey will have the opportunity to answer the question by selecting a specific location using a point, broken line or polygon. In order to differentiate markings on the map, the administrator can set different colors for individual questions and answers. This allows limiting the area available for responses.",
        "model1_7": "After clicking the <span>GENERATE Geo–Survey</span> button, the administrator receives information on whether all data has been correctly filled out and a link to the completed Geo–Survey.",
        "model1_8": "The entire generator is connected to an SQL database where all administrative settings are saved.",
        "model1_9": "<span>Login Panel</span>",
        "model1_10": "The administrator has the ability to create any number of accounts that will have access to the questions in the Geo–Survey. Accounts must be created directly in the dedicated SQL database. Each respondent must first provide login details.",
        "model1_11": "This solution allows the Geo–Survey administrator to verify the responses of a given individual.",
        "model1_12": "If the creator of the Geo–Survey decides that the responses to the questions should be anonymous, they have the option to skip the login panel.",
        "model1_13": "<span>Welcome Panel</span>",
        "model1_14": "This panel initiates participation in the Geo–Survey. The respondent is introduced to the topic of the study in which they are participating. The welcome text was prepared at the stage of generating the Geo–Survey by the administrator. ",
        "model1_15": "After clicking the <span>Start Survey</span> button, the respondent will be directed to the prepared questions. In the upper right corner, there is information about who is logged into the Geo–Survey. There is also an option to withdraw from participation by logging out.",
        "model1_16": "<span>Geo–Survey &ndash; Answering Questions</span>",
        "model1_17": "Panels with map overlays are the key elements of the Geo–Survey. This is where respondents can answer the prepared questions. The number of stages is generated automatically and depends on the number of questions prepared. Each stage consists of a maximum of 2 questions to ensure that markings on the map are clear for the respondent.",
        "model1_18": "After providing answers by marking a point or drawing a line or area, the respondent can proceed to continue the survey. At any time, they can return to the previous stage and change their answers.",
        "model1_19": "<span>Final Panel</span>",
        "model1_20": "The final panel is the last element of the Geo–Survey, where the user receives a thank you note for participating in the prepared study. The text of this thank you note can be personalized during the Geo–Survey generator stage.",
        "model1_21": "After clicking the <span>Log Out and Finish Survey</span> button, the provided answers are finalized and sent to the SQL database along with the identification of the user who provided them.",
        "model2_1": "Cat and dog classification using CNN Keras",
        "model2_2": "May 2024",
        "model2_3": "Recognizing and naming an animal or object is not a major problem for humans. But will it be as easy for a computer with only a photo of the pet? As I am interested in machine learning, I could not pass up such a question. I decided to check whether and how accurately the computer would be able to recognize the animal species shown in a given photo.",
        "model2_4": "Classifying dogs and cats is one of the standard deep learning projects in computer vision that involves classifying realistic photos into two categories. During the project, I first had to load and prepare images for training purposes, and then separate the images into a dataset for training and validation purposes. Next, I used ImageDataGenerator to expand the dataset and reduce overfitting. I developed the CNN model using the KERAS library, and selected parameters to improve its performance. In the next step, I assessed the model's performance, saved and loaded the model for further predictions, and finally performed classification of pets in my family. ",
        "model2_5": "I used a dataset consisting of a total of 25,000 images of dogs and cats. This dataset was first introduced for a Kaggle competition in 2013.",
        "model2_6": "The dataset is available <a href=\"https://www.kaggle.com/datasets/shaunthesheep/microsoft-catsvsdogs-dataset/data/\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> (about 865 MB).",
        "model2_7": "To classify images into two categories: dogs and cats, I applied a convolutional neural network (CNN).",
        "model2_8": "Model architecture:",
        "model2_9": "Layers:",
        "model2_10": "Input layer consists of a Conv2D layer with 32 filters and ReLU activation function.",
        "model2_11": "The model includes 3 convolutional blocks with increasing numbers of filters and ReLU activation.",
        "model2_12": "Each convolutional block contains batch normalization, max pooling (grid size &#61; 2), and a Dropout layer (0.2).",
        "model2_13": "Fully connected layers include a Flatten layer, a Dense layer with 512 units, and a Dropout layer.",
        "model2_14": "The output layer is a Dense layer with 2 units and softmax activation.",
        "model2_15": "Components:",
        "model2_16": "Input layer: Receives input images for classification.",
        "model2_17": "Convolutional layers: Extract features from images using convolutional operations.",
        "model2_18": "Pooling layers: Reduce spatial dimensions of the features.",
        "model2_19": "Flatten layer: Converts 2D feature maps into a 1D vector.",
        "model2_20": "Fully connected layers: Perform classification using densely connected layers.",
        "model2_21": "Output layer: Provides final prediction probabilities for dog and cat classes.",
        "model2_22": "I successfully built a deep neural network model by implementing a convolutional neural network (CNN) with over 6.8 million trainable parameters. This resulted in achieving a very high classification accuracy of <span>about 94%</span> for both dogs and cats.",
        "model2_23": "After training and validating the model, it was time to see whether the computer correctly identified my pets as dogs and cats. Ultimately, the computer confirmed my guess. <span>A complete success.</span>",
        "model3_1": "Diabetes Detection and Risk Factor Assessment",
        "model3_2": "September 2022",
        "model3_3": "Introduction to the Project:",
        "model3_4": "Diabetes is one of the most common chronic diseases in the United States, affecting millions of Americans each year and posing a significant financial burden on the economy. Diabetes is a serious chronic condition that can lead to reduced quality of life and shortened life expectancy. The scale of the problem is also significant. According to data from the Centers for Disease Control and Prevention (CDC), in 2018, 34.2 million Americans had diabetes, and 88 million had prediabetes. Furthermore, the CDC estimates that 1 in 5 people with diabetes and about 8 in 10 people with prediabetes are unaware of their risk.",
        "model3_5": "Although diabetes cannot be cured completely, strategies such as weight loss, healthy eating, physical activity, and pharmacological treatment can mitigate the effects of the disease for many patients. Early diagnosis can lead to lifestyle changes and more effective treatment, making predictive models for assessing diabetes risk an important tools for doctors and public health officials.",
        "model3_6": "Description of the Dataset Used in the Project:",
        "model3_7": "The Behavioral Risk Factor Surveillance System (BRFSS) is an annual health survey conducted by the CDC. Each year, the survey collects responses from over 400,000 Americans across all 50 states about risky health behaviors, chronic conditions, and preventive services use. The BRFSS has been continuously conducted since 1984, making it the largest ongoing health survey system in the world.",
        "model3_8": "For this project, a SAS file with data available on the CDC website for the year 2019 was used. The original dataset contains responses from 418,268 individuals and consists of 342 features. These features include questions directly asked to participants or variables calculated based on individual responses.<a href=\"https://www.cdc.gov/brfss/annual_data/annual_2019.html\" target=\"_blank\" rel=\"noopener noreferrer\">[Link to data]</a>",
        "model3_9": "For the purposes of this analysis, only factors related to diabetes risk were considered. The research work by Zidian Xie titled „Building Risk Prediction Models for Type 2 Diabetes Using Machine Learning Techniques” from 2014 was very helpful in selecting the appropriate features.",
        "model3_10": "Project Objective:",
        "model3_11": "The main goal of this project is to answer the question:",
        "model3_12": "Can the questions from the BRFSS survey provide accurate predictions of whether a person has diabetes?",
        "model3_13": "Results:",
        "model3_14": "The best result for each metric was achieved by <span>the XGBoostClassifier</span> trained on an oversampled dataset.",
        "model3_15": "<span>Accuracy: </span>The result of <span class=\"number\">91,8%</span> on the test set is very good. The model incorrectly classified only 8% of the cases out of all classifications.",
        "model3_16": "<span>F1-score:</span> The score of <span class=\"number\">92%</span> shows how accurately the model classifies examples as „positive” or „negative” in our case, as healthy individuals or those with diabetes.",
        "model3_17": "<span>AUC (Area Under the Curve):</span> AUC measures the classifier's ability to distinguish between classes and is used as a summary of the ROC curve. The higher the AUC, the better the model's performance in distinguishing between positive and negative classes. A score of 0,917 is excellent &ndash; <span class=\"number\">almost 92%</span> of the cases are correctly distinguished by the model.",
        "model3_18": "<span>Recall:</span> A score of <span class=\"number\">almost 96,7%</span> is very good. The model only incorrectly classifies a person as having the disease in 3 out of 100 cases. The model seems very effective in clinical settings, especially since all features are non-invasive measures.",
        "model3_19": "<span>Precision:</span> The precision value of <span class=\"number\">nearly 88%</span> tells us how confident we can be that a given person actually has the disease. It indicates how well the test distinguishes individuals with the disease from those without it. In almost 9 out of 10 cases, we can be sure that the model correctly predicts diabetes in a person who actually has it.",
        "model3_20": "Photo by<a href=\"https://www.freepik.com/author/macrovector\">macrovector</a>from Freepik.",
        "model4_1": "Forecasting Single-Family Home Prices",
        "model4_2": "September 2022",
        "model4_3": "A project aimed at forecasting home prices is an ideal competition for data science enthusiasts looking to expand their machine learning skills. Therefore, I decided to participate in this project on www.kaggle.com.<a href=\"https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data\" target=\"_blank\" rel=\"noopener noreferrer\">[Link to data]</a>",
        "model4_4": "Description of the Data Used in the Project:",
        "model4_5": "The dataset contains 79 different variables describing (almost) every aspect of residential properties in Ames, Iowa, including:",
        "model4_6": "The area of the plot on which the house stands",
        "model4_7": "Access to alley or road, and how many roads are near the property",
        "model4_8": "Type of building as well as style of construction and finishing",
        "model4_9": "Type and quality of heating used",
        "model4_10": "Available utilities",
        "model4_11": "Number of bedrooms, bathrooms, and kitchens, and their quality",
        "model4_12": "Pool area and many other aspects",
        "model4_13": "The goal of the exercise was to develop skills in building creative features and, most importantly, to become familiar with advanced regression techniques. Ultimately, using the best model to predict the price of a residential property.",
        "model4_14": "I developed several regression models, including both basic versions and those with optimized hyperparameters. The best model turned out to be <span>ElasticNet with hyperparameters</span>, which achieved an RMSE of <span>0.1169</span> and an R-Squared of <span>0.915.</span>",
        "model4_15": "Photo by<a href=\"https://pl.freepik.com/autor/freepik\">freepik</a>from Freepik.",
        "model5_1": "The Titanic Disaster",
        "model5_2": "September 2022",
        "model5_3": "Historical Overview:",
        "model5_4": "The story of the Titanic disaster is probably well-known to everyone. It was a luxury British liner that sank during its maiden voyage from Southampton to New York in 1912. It was the largest passenger ship of its time, and its design was considered a marvel of engineering, leading many to believe it was „unsinkable”.",
        "model5_5": "More than 2200 passengers and crew were aboard the Titanic. The passengers included people of various social classes, from the wealthiest people of the time to emigrants seeking a better life in America.",
        "model5_6": "On the night of April 14, 1912, the Titanic collided with an iceberg in the North Atlantic. As a result of the collision, the ship suffered serious damage and began to sink. The disaster claimed the lives of over 1,500 people, making it one of the greatest maritime tragedies in history. Only about 700 people survived, primarily due to lifeboats.",
        "model5_7": "The Titanic disaster has become the subject of numerous studies, including data analysis and machine learning.",
        "model5_8": "Description of the Data Used in the Project:",
        "model5_9": "This project is related to the „Titanic: Machine Learning from Disaster” competition on the Kaggle platform. It is one of the most popular and frequently recommended projects for beginner data scientists and analysts. In this competition, participants are tasked with predicting which Titanic passengers survived the disaster and which unfortunately did not, based on the data provided. The dataset used in the project contains 10 variables that should help achieve this goal.<a href=\"https://www.kaggle.com/competitions/titanic/data\" target=\"_blank\" rel=\"noopener noreferrer\">[Link to data]</a>",
        "model5_10": "Key Features of the Dataset:",
        "model5_11": "Pclass (Passenger Class): 1, 2, or 3.",
        "model5_12": "Name: May contain titles that could be useful.",
        "model5_13": "Sex: An important factor in predicting survival.",
        "model5_14": "Age: Values in some lines are missing and need to be completed.",
        "model5_15": "SibSp (number of siblings/spouses aboard).",
        "model5_16": "Parch (number of parents/children aboard).",
        "model5_17": "Ticket: May contain information about passenger groups.",
        "model5_18": "Fare: May indicate economic status.",
        "model5_19": "Cabin: Many missing values, but potentially useful.",
        "model5_20": "Embarked: C, Q, S.",
        "model5_21": "Results:",
        "model5_22": "PAfter thoroughly analyzing all the variables and cleaning the data, I proceeded to build classification models. In my case, the best model turned out to be the VotingClassifier. The model achieved a cross-validation score of <span>approximately 83.6%</span>.",
        "model5_23": "Photo by<a href=\"https://pl.freepik.com/autor/vectorpouch\">vectorpouch</a>from Freepik.",
        "model6_1": "Own website &ndash; RESUME",
        "model6_2": "Constantly updated",
        "model6_3": "The idea of creating my own portfolio-style website came a long time ago. The motivation for this was, among other things, the desire to share my self-implemented projects from various categories with others. Since it's difficult to present all the achievements on an A4 sheet of paper, I decided to build this website. It serves as an extended interactive resume where I have included information about myself, my professional experience and education, as well as projects with links to their source code.",
        "model6_4": "The website is responsive. I made sure to design it so that it works properly on any device. I plan to continuously update all the information on it and add new projects, both completed and ongoing.",
        "model6_5": "Recently, a new functionality has appeared on the website, namely the ability to view it in English. In the future, a new item in the menu might be introduced &ndash; <span>Blog</span>, where I will post interesting news from the GIS and Data Science industries, or the now popular AI.",
        "model6_6": "If you wish to contact me, please visit <span>the Contact section</span>.",
        "model7_1": "Web Data Extraction &ndash; Web Scraping",
        "model7_2": "March 2022",
        "model7_3": "This project was completed as part of consolidating knowledge gained during the Data Science PRO Bootcamp. It is a small web scraping project, with the main goal being the automatic retrieval of data using Python and the BeautifulSoup library.",
        "model7_4": "Due to my interest in managing personal finances and investing in various assets, including cryptocurrencies, I targeted a website &ndash; <a href=\"https://crypto.com/price/pl\" target=\"_blank\" rel=\"noopener noreferrer\">www.crypto.com</a>, which contains the current rates of all cryptocurrencies.",
        "model7_5": "The project aimed to scrape data from the website for the top 500 coins and save it in an Excel spreadsheet.",
        "model7_6": "Photo by<a href=\"https://pl.freepik.com/autor/freepik\">freepik</a>from Freepik.",
        "model8_1": "Password Generator",
        "model8_2": "April 2022",
        "model8_3": "The password generator is one of the fundamental projects that is typically done during the learning process of various programming languages. This was also the case during my learning of Python.",
        "model8_4": "The application assumed that the user would provide a few details:",
        "model8_5": "For which website/application the password is intended.",
        "model8_6": "What username is associated with the password.",
        "model8_7": "The minimum length of the generated password.",
        "model8_8": "Whether the password should include numbers.",
        "model8_9": "Whether the password should include special characters.",
        "model8_10": "The generated passwords are saved to a file. In the future, this feature could be expanded by replacing the standard TXT file with, for example, a database protected by a password.",
        "model8_11": "I didn’t want this generator to be a typical, standard project. That’s why I also decided to create a simple GUI for it in Python.",
        "model8_12": "Photo by<a href=\"https://pl.freepik.com/autor/freepik\">freepik</a>from Freepik.",
        "model9_1": "Wedding Invitations",
        "model9_2": "June 2024",
        "model9_3": "Working on graphic design projects is something I really enjoy doing, especially when it involves helping friends. This was the case here. The project involved designing wedding invitations in A5 format, along with place cards to be placed on the tables and labels for gifts that the newlyweds wanted to give to their guests.",
        "model9_4": "The theme of the invitations was forest, as the wedding and reception took place in such a scenery.",
        "model9_5": "Sources of the graphic design:",
        "model9_6": "Background used in the project &ndash; pastel forest:",
        "model9_7": "Author: <a href=\"https://pl.freepik.com/autor/pickoloh\" target=\"_blank\" rel=\"noopener noreferrer\"> pickoloh </a> | Portal: <a href=\"https://www.freepik.com\" target=\"_blank\" rel=\"noopener noreferrer\"> www.freepik.com</a>",
        "model9_8": "Icons used in the project:",
        "model9_9": "Author: Mateusz Wuchnicki",
        "model9_10": "Font used in the project:",
        "model10_1": "Wedding Invitations",
        "model10_2": "June 2024",
        "model10_3": "Working on graphic design projects is something I really enjoy doing, especially when it involves helping friends. This was the case here. The project involved designing wedding invitations in A5 format, along with place cards to be placed on the tables and labels for gifts that the newlyweds wanted to give to their guests.",
        "model10_4": "The theme of the invitations was flowers with a predominant pink color.",
        "model10_5": "Sources of the graphic design:",
        "model10_6": "Background used in the project &ndash; pastel forest:",
        "model10_7": "Author: <a href=\"https://it.freepik.com/autore/dede-sumiarsih\" target=\"_blank\" rel=\"noopener noreferrer\"> dede-sumiarsih </a> | Portal: <a href=\"https://www.freepik.com\" target=\"_blank\" rel=\"noopener noreferrer\"> www.freepik.com</a>",
        "model10_8": "Icons used in the project:",
        "model10_9": "Author: Mateusz Wuchnicki",
        "model10_10": "Font used in the project:",
        "model11_1": "Logo and Business Cards",
        "model11_2": "October 2018",
        "model11_3": "The project involved creating a new logo and business cards for a company providing geodetic services.",
        "model11_4": "The logo was to include the name of the sole proprietor and clearly convey the surveying theme. Therefore, <span>the letter A</span> was designed to represent a surveying instrument &ndash; a total station &ndash; while <span>the letter I</span> was designed to resemble a leveling rod." 
    }
}